{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_randfloat\n",
    "\n",
    "nfl = pd.read_csv(\"NFL_data_super_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to an array\n",
    "play = array(nfl[\"play_type\"])\n",
    "\n",
    "# encode as integers\n",
    "play_encoder = LabelEncoder()\n",
    "play_encoded =  play_encoder.fit_transform(play) \n",
    " \n",
    "# binary encode\n",
    "play_onehot_encoder = OneHotEncoder(sparse=False) # disable sparse return type\n",
    "# reshape the array\n",
    "play_encoded = play_encoded.reshape(len(play_encoded), 1) \n",
    "play_onehot_encoded = play_onehot_encoder.fit_transform(play_encoded)\n",
    "\n",
    "nfl[\"play_type\"] = play_onehot_encoded.tolist()\n",
    "\n",
    "posteam = array(nfl[\"posteam\"])\n",
    "\n",
    "# encode as integers\n",
    "posteam_encoder = LabelEncoder()\n",
    "posteam_encoded =  posteam_encoder.fit_transform(posteam) \n",
    " \n",
    "# binary encode\n",
    "posteam_onehot_encoder = OneHotEncoder(sparse=False) # disable sparse return type\n",
    "# reshape the array\n",
    "posteam_encoded = posteam_encoded.reshape(len(posteam_encoded), 1) \n",
    "posteam_onehot_encoded = pd.DataFrame(posteam_onehot_encoder.fit_transform(posteam_encoded))\n",
    "\n",
    "nfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "nfl1 = nfl.drop(columns = ['posteam'])\n",
    "nfl2 = posteam_onehot_encoded.join(nfl1)\n",
    "nfl2.columns = ['ARI', 'ATL', 'BAL', 'BUF', 'CAR', 'CHI', 'CIN', 'CLE', 'DAL', 'DEN', 'DET', \n",
    "'GB', 'HOU', 'IND', 'JAX', 'KC', 'LAC', 'LAR', 'LV', 'MIA', 'MIN', 'NE', 'NO', 'NYG', 'NYJ', \n",
    "'PHI', 'PIT', 'SEA', 'SF', 'TB', 'TEN', 'WAS', 'yardline_100', 'quarter_seconds_remaining', \n",
    "'qtr', 'down', 'goal_to_go', 'ydstogo', 'score_margin', 'play_type']\n",
    "\n",
    "nfl2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl3 = nfl2.copy()\n",
    "scaler = MinMaxScaler()\n",
    "for column_name in ['yardline_100','quarter_seconds_remaining','qtr','down','goal_to_go','ydstogo','score_margin']:\n",
    "    col = nfl3[column_name]\n",
    "    scaled = scaler.fit_transform(nfl3[column_name].values.reshape(-1, 1))\n",
    "    nfl3[column_name] = scaled\n",
    "nfl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nfl3.drop(\"play_type\", axis = 1)\n",
    "y = play_onehot_encoded\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "clf = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.3, batch_size = 100, hidden_layer_sizes = (40, 3), max_iter = 500)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = clf.predict_proba(X_test)\n",
    "n = 0\n",
    "for idx, x in enumerate(prob):\n",
    "    for idx, y in enumerate(x):\n",
    "        if y == max(x):\n",
    "            x[idx] = 1\n",
    "        else:\n",
    "            x[idx] = 0\n",
    "newy_pred = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a confusion matrix\n",
    "print(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, newy_pred)\n",
    "print('MSE:', mse)\n",
    "\n",
    "print(classification_report(y_test, newy_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_num = 1\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "for train, test in kfold.split(X, play_onehot_encoded):\n",
    "    model = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.3, batch_size = 100, hidden_layer_sizes = (40, 3), max_iter = 500)\n",
    "    hist = model.fit(X.iloc[train], play_onehot_encoded[train])\n",
    "    score = model.score(X.iloc[test], play_onehot_encoded[test])\n",
    "    y_pred = model.predict(X.iloc[test])\n",
    "    prob = clf.predict_proba(X_test)\n",
    "    n = 0\n",
    "    for idx, x in enumerate(prob):\n",
    "        for idx, y in enumerate(x):\n",
    "            if y == max(x):\n",
    "                x[idx] = 1\n",
    "            else:\n",
    "                x[idx] = 0\n",
    "    newy_pred = prob\n",
    "    mse = mean_squared_error(y_test, newy_pred)\n",
    "    print(f'Fold {fold_num} - Accuracy: {score:.3f}; Loss: {mse:.3f}')\n",
    "    acc_per_fold.append(score)\n",
    "    loss_per_fold.append(mse)\n",
    "    fold_num = fold_num + 1\n",
    "   \n",
    "print('Average Accuracy: %.3f' % (mean(acc_per_fold)))\n",
    "print('Average Loss: %.3f' % (mean(loss_per_fold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertuner = RandomizedSearchCV(estimator = clf, param_distributions = {\n",
    "    'hidden_layer_sizes': (3,40),(40,),\n",
    "    'learning_rate_init': sp_randfloat(0.1,0.3),\n",
    "}, cv=5, return_train_score=False,n_jobs = 5)\n",
    "hypertuner.fit(X, play_onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % hypertuner.best_score_)\n",
    "print('Best Hyperparameters: %s' % hypertuner.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = hypertuner.best_estimator_\n",
    "print(\"Accuracy:\", bestModel.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a7891ce5105f8b56b367cc50435b1906045e7b0c9dc8ce29244bbcc2793d18c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
